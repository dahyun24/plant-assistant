import os
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import Optional
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from langchain_huggingface import HuggingFaceEmbeddings

# Milvus ì—°ê²°
connections.connect(alias="default", uri="http://localhost:19530")

sensor_fields = [
    "AirTemperature", "AirHumidity", "Co2", "Quantum",
    "HighSoilTemp", "HighSoilHumi", "LowSoilTemp", "LowSoilHumi"
]

embeddings = HuggingFaceEmbeddings(model_name="dragonkue/BGE-m3-ko", show_progress=False)

# Multi-Vector ì»¬ë ‰ì…˜ ìƒì„±
collection_name = "plant_multi_vector"

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=1024),
    FieldSchema(name="sensor_vector", dtype=DataType.FLOAT_VECTOR, dim=8),
    FieldSchema(name="plant_name", dtype=DataType.VARCHAR, max_length=50),
    FieldSchema(name="growth_level", dtype=DataType.VARCHAR, max_length=10),
    FieldSchema(name="place", dtype=DataType.VARCHAR, max_length=20),
    FieldSchema(name="image_name", dtype=DataType.VARCHAR, max_length=100),
]

schema = CollectionSchema(fields, description="Plant multi-vector collection (text + sensor)")

if collection_name not in utility.list_collections():
    collection = Collection(name=collection_name, schema=schema)
else:
    collection = Collection(name=collection_name)

print(f"âœ… Collection ready: {collection_name}")


def folder_for_caption(caption_path: Path) -> Optional[Path]:
    """ìº¡ì…˜ íŒŒì¼ëª… ê¸°ì¤€ìœ¼ë¡œ JSON í´ë” ê²½ë¡œ ë§¤í•‘"""
    name = caption_path.name
    if "ë³´ìŠ¤í„´ê³ ì‚¬ë¦¬" in name:
        return Path("VL_A.á„’á…ªá„á…©_3.á„‰á…³á†¸á„‰á…¢á†¼á„‰á…µá†¨á„†á…®á†¯_08.á„‡á…©á„‰á…³á„á…¥á†«á„€á…©á„‰á…¡á„…á…µ")
    if "ìŠ¤íŒŒí‹°í•„ëŸ¼" in name:
        return Path("VL_A.á„’á…ªá„á…©_2.á„Œá…®á†¼á„‰á…¢á†¼á„‰á…µá†¨á„†á…®á†¯_07.á„‰á…³á„‘á…¡á„á…µá„‘á…µá†¯á„…á…¥á†·")
    return None


def extract_sensor_vector(json_path: Path) -> list[float]:
    """ì„¼ì„œê°’ 8ê°œ ì¶”ì¶œ"""
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        sensor = data.get("sensor", {})
        vec = []
        for key in sensor_fields:
            try:
                vec.append(float(sensor.get(key, 0.0)))
            except ValueError:
                vec.append(0.0)
        return vec


def build_combined_text(data: dict, caption_text: str) -> str:
    """í…ìŠ¤íŠ¸ ì„ë² ë”©ìš© ë¬¸ì¥ ìƒì„±"""
    t = (
        f"{data['plant']['PlantName']}ëŠ” "
        f"{data['info']['Place']}ì—ì„œ ìë¼ëŠ” {data['plant']['PlantClass']}ì´ë©°, "
        f"í™˜ê²½ì€ {data['plant']['Environment']} ìƒíƒœì´ê³  "
        f"ìƒì¥ ê²°ê³¼ëŠ” {data['info']['ResultOfGrowthLevel']}ì´ë‹¤. "
        f"í˜„ì¬ {data['watering']['IrrigationState']} ìƒíƒœì´ê³ , "
        f"ê´€ìˆ˜ëŸ‰ì€ {data['watering']['AmtIrrigation']}mlì´ë‹¤."
    )
    return f"[ì‹ë¬¼ ì •ë³´]\n{t}\n\n[ì´ë¯¸ì§€ ì„¤ëª…]\n{caption_text}"

# ë°ì´í„° ì‚½ì… ë£¨í”„
caption_paths = [
    Path("ì „ì²´ë³´ìŠ¤í„´ê³ ì‚¬ë¦¬_ìº¡ì…˜.json"),
    Path("ì „ì²´ìŠ¤íŒŒí‹°í•„ëŸ¼_ìº¡ì…˜2.json"),
]

BATCH_SIZE = 50
total_added = 0

for caption_path in caption_paths:
    json_dir = folder_for_caption(caption_path)
    if not json_dir:
        print(f"âš ï¸ í´ë” ë§¤í•‘ ì‹¤íŒ¨: {caption_path.name}")
        continue

    with open(caption_path, "r", encoding="utf-8") as f:
        caption_data = json.load(f)

    text_vecs, sensor_vecs, plant_names, growth_levels, places, image_names = [], [], [], [], [], []

    for idx, item in enumerate(tqdm(caption_data, desc=f"Processing {caption_path.name}"), start=1):
        image_name = item.get("image_name")
        caption_text = item.get("Gemini_Caption", "")
        if not image_name:
            continue

        json_file = json_dir / f"{Path(image_name).stem}.json"
        if not json_file.exists():
            continue

        with open(json_file, "r", encoding="utf-8") as jf:
            data = json.load(jf)

        combined_text = build_combined_text(data, caption_text)
        text_vector = np.array(embeddings.embed_query(combined_text))
        sensor_vector = np.array(extract_sensor_vector(json_file))

        text_vecs.append(text_vector.tolist())
        sensor_vecs.append(sensor_vector.tolist())
        plant_names.append(data["plant"]["PlantName"])
        growth_levels.append(data["info"]["ResultOfGrowthLevel"])
        places.append(data["info"]["Place"])
        image_names.append(image_name)

        if len(text_vecs) >= BATCH_SIZE:
            collection.insert([
                text_vecs, sensor_vecs, plant_names,
                growth_levels, places, image_names
            ])
            total_added += len(text_vecs)
            print(f"âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ (+{len(text_vecs)}ê°œ, ëˆ„ì  {total_added})")
            text_vecs, sensor_vecs, plant_names, growth_levels, places, image_names = [], [], [], [], [], []

    # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
    if text_vecs:
        collection.insert([
            text_vecs, sensor_vecs, plant_names,
            growth_levels, places, image_names
        ])
        total_added += len(text_vecs)
        print(f"âœ… ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (+{len(text_vecs)}ê°œ, ëˆ„ì  {total_added})")

print(f"ğŸ‰ ì „ì²´ ì™„ë£Œ! ì´ {total_added}ê°œ ë¬¸ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 8ï¸âƒ£ ì¸ë±ìŠ¤ ìƒì„± ë° ì»¬ë ‰ì…˜ ë¡œë“œ
print("\nğŸ” Milvus ì¸ë±ìŠ¤ ìƒì„± ë° ì»¬ë ‰ì…˜ ë¡œë“œ ì‹œì‘...")

# 1. text_vector (1024 dim) ì¸ë±ìŠ¤ ì„¤ì •: IVF_FLAT (ANN ê²€ìƒ‰)
index_params_text = {
    "index_type": "IVF_FLAT", 
    "metric_type": "COSINE", 
    "params": {"nlist": 128}  # nlistëŠ” ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
}

# 2. sensor_vector (8 dim) ì¸ë±ìŠ¤ ì„¤ì •: FLAT (100% ì •í™•ë„)
index_params_sensor = {
    "index_type": "FLAT", 
    "metric_type": "L2", 
    "params": {} 
}

# ì¸ë±ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
if not collection.has_index():
    print("â³ ì¸ë±ìŠ¤ ìƒì„± ì¤‘... (ë°ì´í„° ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    try:
        # text_vectorì— ì¸ë±ìŠ¤ ìƒì„±
        collection.create_index(field_name="text_vector", index_params=index_params_text)
        # sensor_vectorì— ì¸ë±ìŠ¤ ìƒì„±
        collection.create_index(field_name="sensor_vector", index_params=index_params_sensor)
        print("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    print("âœ… ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
# ê²€ìƒ‰ì„ ìœ„í•´ ì»¬ë ‰ì…˜ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ (í•„ìˆ˜)
try:
    collection.load()
    print("âœ… ì»¬ë ‰ì…˜ ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ: ì´ì œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âŒ ì»¬ë ‰ì…˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")